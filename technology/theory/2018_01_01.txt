1.heaviside step function (亦称单位阶跃函数) - 非黑即白 - 非0即1
2.决策边界图是什么？包含一条分割两种数据点的直线的图。
3.梯度上升思想：要寻找某个函数的最大值，最好的方式就是沿着该函数的梯度方向寻找。
4.梯度算子是什么？函数是数到数的映射;泛化函数时函数到数的映射;算子是函数到函数的映射。
5.梯度上升(gradient ascent)算法用来求函数的最大值;而梯度下降(descent)算法求的是函数的最小值。
6.math.exp() vs numpy.exp()
7.随机梯度上升算法: 一次仅用一个样本点来更新回归系数(样本随机选择)。
8.如何处理数据集中的数据缺失问题？均值(可用特征、相似样本)、特殊值、忽略、通过机器学习算法预测
9.预处理(preprocess): ①处理缺省值(特征、类别)。②当类别标签(classList)出现缺省值时,选择放弃该条数据。
10.如何使用Logistic回归算法进行分类？把数据集上的每个特征向量乘以最优方法得来的最佳回归系数,再对该乘积结果求和，
并作为z传入sigmoid函数。若大于0.5,则类别标签为1,否则为0。
×11.RuntimeWarning: overflow encountered in exp: return 1.0 / (1 + np.exp(-x))? - dtype = np.float128
12.什么是最优化算法: 常用的 - (随机)梯度上升(下降)算法
